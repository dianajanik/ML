{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import functools\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, training_set, labels):\n",
    "        self.k = len(labels)\n",
    "        self.labels = labels\n",
    "        self.prios = np.zeros(self.k)\n",
    "        words_classes = [ [word_tokenize(training_sentence) for training_sentence in training_text ]\n",
    "                                                            for training_text in training_set]\n",
    "        words_classes = []\n",
    "        for i in range(self.k):\n",
    "            w_i = [word_tokenize(training_sentence) for training_sentence in training_set[i]]\n",
    "            words_classes.append(functools.reduce(lambda a,b : a + b, w_i))\n",
    "            \n",
    "        training_set_len = sum(sum(len(word) for word in words) for words in words_classes)\n",
    "        self.likelihood = [{} for _ in range(self.k)]\n",
    "        for i in range(self.k):\n",
    "            self.likelihood[i] = {word : (words_classes[i].count(word) + 0.5) \n",
    "                                              / (len(words_classes[i]) + 0.5) \n",
    "                                              for word in words_classes[i]}\n",
    "        \n",
    "        self.priors = [len(words_classes[i]) / training_set_len for i in range(self.k)]\n",
    "        \n",
    "    def predict(self, text):\n",
    "        probabilities = self._get_probabilities(text)\n",
    "        max_index, max_value = max(enumerate(probabilities), key=operator.itemgetter(1))\n",
    "        return self.labels[max_index]\n",
    "    \n",
    "    def _get_probabilities(self, text):\n",
    "        words = word_tokenize(text)\n",
    "        probabilities = []\n",
    "        for i in range(self.k):\n",
    "            words_probabilities = [self.likelihood[i][word] if word in self.likelihood[i] \n",
    "                                   else np.finfo(np.float32).eps for word in words]\n",
    "            probabilities.append(functools.reduce(operator.mul, words_probabilities, 1))\n",
    "        return probabilities\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed model with training data\n",
    "Data used to train and test this data can be found on webpage : https://archive.ics.uci.edu/ml/machine-learning-databases/00331/ \n",
    "\n",
    "Model is train based on \"yelp_labelled.txt\" file and tested based on \"amazon_cells_labelled.txt\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def devide_data(data):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    for sentence, label in zip(data['sentence'], data['label']):\n",
    "        if label == 1:\n",
    "            positive.append(sentence)\n",
    "        else:\n",
    "            negative.append(sentence)\n",
    "            \n",
    "    return (positive, negative)\n",
    "    \n",
    "training_data = pd.read_csv('yelp_labelled.txt', sep=\"\\t\")\n",
    "training_data.columns = [\"sentence\", \"label\"]\n",
    "positive, negative = devide_data(training_data)\n",
    "\n",
    "nb = NaiveBayes([positive, negative], [1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import testing data & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = pd.read_csv('amazon_cells_labelled.txt', sep=\"\\t\")\n",
    "testing_data.columns = [\"sentence\", \"label\"]\n",
    "predictions_naive_bayes = [ nb.predict(sentence) for sentence in testing_data['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[379 120]\n",
      " [184 316]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Predicted label')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Generate confusion matrix:\n",
    "conf_mat=confusion_matrix(testing_data['label'], predictions_naive_bayes)\n",
    "print(\"Confusion matrix : \\n {}\".format(conf_mat))\n",
    "conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_mat_normalized)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956956956956957\n"
     ]
    }
   ],
   "source": [
    "# Accuracy \n",
    "accuracy = {}\n",
    "accuracy['naive_bayes'] = accuracy_score(testing_data['label'],predictions_naive_bayes)\n",
    "print(str(accuracy['naive_bayes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7247706422018348\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(testing_data['label'],predictions_naive_bayes)\n",
    "print(str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632\n"
     ]
    }
   ],
   "source": [
    "#Recall score\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score = recall_score(testing_data['label'],predictions_naive_bayes)\n",
    "print(str(recall_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with other classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_positive, data_negative, features=None):\n",
    "    if features is None:\n",
    "        _features = functools.reduce(lambda a,b : a + b, [data_positive, data_negative])\n",
    "        features = list(set(functools.reduce(lambda a,b : a + b, _features)))\n",
    "    \n",
    "    Y = [1 for _ in range(len(data_positive))] + [0 for _ in range(len(data_negative))]\n",
    "    sentence_features = [0 for _ in range(len(features))]\n",
    "    total_len = len(data_positive) + len(data_negative)\n",
    "    X = [sentence_features for _ in range(total_len)]\n",
    "\n",
    "    for sentence, i in zip(data_positive + data_negative, range(total_len)):\n",
    "        words = word_tokenize(sentence)\n",
    "        words = list(set(words))\n",
    "        for word in words:\n",
    "            occurance = words.count(word)\n",
    "            if word in features:\n",
    "                index = features.index(word)\n",
    "                X[i][index] = occurance\n",
    "                \n",
    "    return(X,Y, features)\n",
    "    \n",
    "    \n",
    "# prepare training data\n",
    "training_X, training_Y, features = prepare_data(positive, negative)\n",
    "\n",
    "# prepare test data\n",
    "positive_test, negative_test = devide_data(testing_data)\n",
    "testing_X, testing_Y, features = prepare_data(positive_test, negative_test, features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes from sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5005005005005005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "snb = MultinomialNB()\n",
    "snb.fit(training_X, training_Y)\n",
    "\n",
    "naive_bayes_sklearn_predictions = snb.predict(testing_X)\n",
    "accuracy['sklearn_naive_bayes'] = accuracy_score(testing_Y, naive_bayes_sklearn_predictions)\n",
    "print(str(accuracy['sklearn_naive_bayes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression from sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4994994994994995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(training_X, training_Y)\n",
    "logistic_regression_predictions = model.predict(testing_X)\n",
    "accuracy['logistic_regression'] = accuracy_score(testing_Y, logistic_regression_predictions)\n",
    "print(str(accuracy['logistic_regression']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-NN classifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5005005005005005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(training_X, training_Y)\n",
    "knn_predictions = model.predict(testing_X)\n",
    "accuracy['k_nn'] = accuracy_score(testing_Y,knn_predictions)\n",
    "print(str(accuracy['k_nn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy : 0.6956956956956957 with model : naive_bayes  \n"
     ]
    }
   ],
   "source": [
    "best = max(accuracy.items(), key=operator.itemgetter(1))[0]\n",
    "print(\"Best accuracy : {} with model : {}  \".format(accuracy[best], best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With given data set my custom model of Naive Bayes turn out to be a bit beter the other ones from Sklean library when taking into consideration accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
